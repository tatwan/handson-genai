{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset:  covtype.csv\n",
    "\n",
    "Source: Remote Sensing and GIS Program, Department of Forest Sciences, College of Natural Resources, Colorado State University\n",
    "\n",
    "Description: Predicting forest cover type from cartographic variables only (no remotely sensed data). The actual forest cover type for a given observation (30 x 30 meter cell) was determined from US Forest Service (USFS) Region 2 Resource Information System (RIS) data. Independent variables were derived from data originally obtained from US Geological Survey (USGS) and USFS data. Data is in raw form (not scaled) and contains binary (0 or 1) columns of data for qualitative independent variables (wilderness areas and soil types).\n",
    "\n",
    "This study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. These areas represent forests with minimal human-caused disturbances, so that existing forest cover types are more a result of ecological processes rather than forest management practices.\n",
    "\n",
    "Variables/Columns\n",
    "\n",
    "- Elevation: Elevation in meters\n",
    "- Aspect: Aspect in degrees azimuth\n",
    "- Slope: Slope in degrees\n",
    "- Horizontal_Distance_To_Hydrology: Horz Dist to nearest surface water features\n",
    "- Vertical_Distance_To_Hydrology: Vert Dist to nearest surface water features\n",
    "- Horizontal_Distance_To_Roadways: Horz Dist to nearest roadway\n",
    "- Hillshade_9am: Hillshade index at 9am, summer solstice\n",
    "- Hillshade_Noon: Hillshade index at noon, summer soltice\n",
    "- Hillshade_3pm: Hillshade index at 3pm, summer solstice\n",
    "- Horizontal_Distance_To_Fire_Points: Horz Dist to nearest wildfire ignition points\n",
    "- Wilderness_Area: 0 (absence) or 1 (presence)\n",
    "- Cover_Type: (2 types) Forest Cover Type designation\n",
    "    - 0: Spruce/Fir\n",
    "    - 1: Lodgepole Pine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the forest cover dataset\n",
    "df = pd.read_csv('../Resources/covtype.csv')\n",
    "X = df.drop('cover', axis=1)\n",
    "y = df['cover']\n",
    "target_names = [\"Spruce/Fir\", \"Lodgepole Pine\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a Random Forests classifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    Spruce/Fir       0.88      0.85      0.86      5346\n",
      "Lodgepole Pine       0.89      0.91      0.90      7033\n",
      "\n",
      "      accuracy                           0.88     12379\n",
      "     macro avg       0.88      0.88      0.88     12379\n",
      "  weighted avg       0.88      0.88      0.88     12379\n",
      "\n",
      "Training Score: 1.0\n",
      "Testing Score: 0.8830277082155263\n"
     ]
    }
   ],
   "source": [
    "# Fit a model, and then print a classification report\n",
    "clf = RandomForestClassifier(random_state=1).fit(X_train_scaled, y_train)\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import an Extremely Random Trees classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    Spruce/Fir       0.89      0.85      0.87      5346\n",
      "Lodgepole Pine       0.89      0.92      0.90      7033\n",
      "\n",
      "      accuracy                           0.89     12379\n",
      "     macro avg       0.89      0.88      0.88     12379\n",
      "  weighted avg       0.89      0.89      0.89     12379\n",
      "\n",
      "Training Score: 1.0\n",
      "Testing Score: 0.8872283706276759\n"
     ]
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier(random_state=1).fit(X_train_scaled, y_train)\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import an Adaptive Boosting classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    Spruce/Fir       0.74      0.72      0.73      5346\n",
      "Lodgepole Pine       0.79      0.81      0.80      7033\n",
      "\n",
      "      accuracy                           0.77     12379\n",
      "     macro avg       0.77      0.77      0.77     12379\n",
      "  weighted avg       0.77      0.77      0.77     12379\n",
      "\n",
      "Training Score: 0.7708423093494183\n",
      "Testing Score: 0.7711446805073108\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(random_state=1).fit(X_train_scaled, y_train)\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    Spruce/Fir       0.74      0.72      0.73      5346\n",
      "Lodgepole Pine       0.79      0.81      0.80      7033\n",
      "\n",
      "      accuracy                           0.77     12379\n",
      "     macro avg       0.77      0.77      0.77     12379\n",
      "  weighted avg       0.77      0.77      0.77     12379\n",
      "\n",
      "Training Score: 0.7736697544161999\n",
      "Testing Score: 0.7711446805073108\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    Spruce/Fir       0.74      0.72      0.73      5346\n",
      "Lodgepole Pine       0.79      0.81      0.80      7033\n",
      "\n",
      "      accuracy                           0.77     12379\n",
      "     macro avg       0.77      0.77      0.77     12379\n",
      "  weighted avg       0.77      0.77      0.77     12379\n",
      "\n",
      "Training Score: 0.7770088323998277\n",
      "Testing Score: 0.772356410049277\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    Spruce/Fir       0.74      0.72      0.73      5346\n",
      "Lodgepole Pine       0.79      0.81      0.80      7033\n",
      "\n",
      "      accuracy                           0.77     12379\n",
      "     macro avg       0.77      0.77      0.77     12379\n",
      "  weighted avg       0.77      0.77      0.77     12379\n",
      "\n",
      "Training Score: 0.7698728996122362\n",
      "Testing Score: 0.769044349301236\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    Spruce/Fir       0.74      0.72      0.73      5346\n",
      "Lodgepole Pine       0.79      0.81      0.80      7033\n",
      "\n",
      "      accuracy                           0.77     12379\n",
      "     macro avg       0.77      0.77      0.77     12379\n",
      "  weighted avg       0.77      0.77      0.77     12379\n",
      "\n",
      "Training Score: 0.7756893580353296\n",
      "Testing Score: 0.7738912674691009\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    Spruce/Fir       0.74      0.72      0.73      5346\n",
      "Lodgepole Pine       0.79      0.81      0.80      7033\n",
      "\n",
      "      accuracy                           0.77     12379\n",
      "     macro avg       0.77      0.77      0.77     12379\n",
      "  weighted avg       0.77      0.77      0.77     12379\n",
      "\n",
      "Training Score: 0.7778974579922447\n",
      "Testing Score: 0.7768802003392843\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    Spruce/Fir       0.74      0.72      0.73      5346\n",
      "Lodgepole Pine       0.79      0.81      0.80      7033\n",
      "\n",
      "      accuracy                           0.77     12379\n",
      "     macro avg       0.77      0.77      0.77     12379\n",
      "  weighted avg       0.77      0.77      0.77     12379\n",
      "\n",
      "Training Score: 0.7785706591986212\n",
      "Testing Score: 0.7772841101866064\n"
     ]
    }
   ],
   "source": [
    "# BONUS\n",
    "def model_tester(model, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    clf = model.fit(X_train_scaled, y_train)\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "    print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')\n",
    "    \n",
    "model_tester(AdaBoostClassifier(random_state=1, n_estimators=100), X, y)\n",
    "model_tester(AdaBoostClassifier(random_state=1, n_estimators=200), X, y)\n",
    "model_tester(AdaBoostClassifier(random_state=1, n_estimators=200, learning_rate=0.1), X, y)\n",
    "model_tester(AdaBoostClassifier(random_state=1, n_estimators=500, learning_rate=0.1), X, y)\n",
    "model_tester(AdaBoostClassifier(random_state=1, n_estimators=1000, learning_rate=0.1), X, y)\n",
    "model_tester(AdaBoostClassifier(random_state=1, n_estimators=2000, learning_rate=0.1), X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
